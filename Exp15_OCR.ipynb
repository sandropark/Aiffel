{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea58e070",
   "metadata": {},
   "source": [
    "# OCR(Optical Character Recognition, 광학 문자 인식)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72644d4f",
   "metadata": {},
   "source": [
    "기계가 문자를 읽는 과정은 1) Detection : 문자의 존재를 인식 2) Recognition : 어떤 문자인지 판독"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77482da",
   "metadata": {},
   "source": [
    "이미지 내의 문자 인식 모델의 기본적인 방법 중 하나는 CNN과 RNN을 결합한 CRNN 모델이다. 이미니 내의 텍스트와 연관된 특징을 CNN을 통해 추출한 후에 스텝 단위의 문자 정보를 RNN으로 인식한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d27fd9",
   "metadata": {},
   "source": [
    "## keras-ocr 써보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6dbf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "\n",
    "# keras-ocr이 detector과 recognizer를 위한 모델을 자동으로 다운로드받게 됩니다. \n",
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea36d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트에 사용할 이미지 url을 모아 봅니다. 추가로 더 모아볼 수도 있습니다. \n",
    "image_urls = [\n",
    "  'https://source.unsplash.com/M7mu6jXlcns/640x460',\n",
    "  'https://source.unsplash.com/6jsp4iHc8hI/640x460',\n",
    "  'https://source.unsplash.com/98uYQ-KupiE',\n",
    "  'https://source.unsplash.com/j9JoYpaJH3A',\n",
    "  'https://source.unsplash.com/eBkEJ9cH5b4'\n",
    "]\n",
    "\n",
    "images = [ keras_ocr.tools.read(url) for url in image_urls]\n",
    "prediction_groups = [pipeline.recognize([url]) for url in image_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4816a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions\n",
    "fig, axs = plt.subplots(nrows=len(images), figsize=(20, 20))\n",
    "for idx, ax in enumerate(axs):\n",
    "    keras_ocr.tools.drawAnnotations(image=images[idx], \n",
    "                                    predictions=prediction_groups[idx][0], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae711e",
   "metadata": {},
   "source": [
    "## 테서랙트 써보기\n",
    "\n",
    "### 1) 테서랙트 설치\n",
    "### 2) 테서랙트 파이썬 wrapper 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31597b66",
   "metadata": {},
   "source": [
    "### 3) 테서랙트로 문자 검출하고 이미지 자르기 (detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0879ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pytesseract import Output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OCR Engine modes(–oem):\n",
    "# 0 - Legacy engine only.\n",
    "# 1 - Neural nets LSTM engine only.\n",
    "# 2 - Legacy + LSTM engines.\n",
    "# 3 - Default, based on what is available.\n",
    "\n",
    "# Page segmentation modes(–psm):\n",
    "# 0 - Orientation and script detection (OSD) only.\n",
    "# 1 - Automatic page segmentation with OSD.\n",
    "# 2 - Automatic page segmentation, but no OSD, or OCR.\n",
    "# 3 - Fully automatic page segmentation, but no OSD. (Default)\n",
    "# 4 - Assume a single column of text of variable sizes.\n",
    "# 5 - Assume a single uniform block of vertically aligned text.\n",
    "# 6 - Assume a single uniform block of text.\n",
    "# 7 - Treat the image as a single text line.\n",
    "# 8 - Treat the image as a single word.\n",
    "# 9 - Treat the image as a single word in a circle.\n",
    "# 10 - Treat the image as a single character.\n",
    "# 11 - Sparse text. Find as much text as possible in no particular order.\n",
    "# 12 - Sparse text with OSD.\n",
    "# 13 - Raw line. Treat the image as a single text line, bypassing hacks that are Tesseract-specific.\n",
    "\n",
    "def crop_word_regions(image_path='./images/sample.png', output_path='./output'):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "    custom_oem_psm_config = r'--oem 3 --psm 3'\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    recognized_data = pytesseract.image_to_data(\n",
    "        image, lang='eng',    # 한국어라면 lang='kor'\n",
    "        config=custom_oem_psm_config,\n",
    "        output_type=Output.DICT\n",
    "    )\n",
    "    \n",
    "    top_level = max(recognized_data['level'])\n",
    "    index = 0\n",
    "    cropped_image_path_list = []\n",
    "    for i in range(len(recognized_data['level'])):\n",
    "        level = recognized_data['level'][i]\n",
    "    \n",
    "        if level == top_level:\n",
    "            left = recognized_data['left'][i]\n",
    "            top = recognized_data['top'][i]\n",
    "            width = recognized_data['width'][i]\n",
    "            height = recognized_data['height'][i]\n",
    "            \n",
    "            output_img_path = os.path.join(output_path, f\"{str(index).zfill(4)}.png\")\n",
    "            print(output_img_path)\n",
    "            cropped_image = image.crop((\n",
    "                left,\n",
    "                top,\n",
    "                left+width,\n",
    "                top+height\n",
    "            ))\n",
    "            cropped_image.save(output_img_path)\n",
    "            cropped_image_path_list.append(output_img_path)\n",
    "            index += 1\n",
    "    return cropped_image_path_list\n",
    "\n",
    "\n",
    "work_dir = os.getenv('HOME')+'/aiffel/ocr_python'\n",
    "img_file_path = work_dir + '/test_img.jpg'   #테스트용 이미지 경로입니다. 본인이 선택한 파일명으로 바꿔주세요. \n",
    "\n",
    "cropped_image_path_list = crop_word_regions(img_file_path, work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd3f96",
   "metadata": {},
   "source": [
    "### 4) 테서랙트로 잘린 이미지에서 단어 인식하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_images(cropped_image_path_list):\n",
    "    custom_oem_psm_config = r'--oem 3 --psm 7'\n",
    "    \n",
    "    for image_path in cropped_image_path_list:\n",
    "        image = Image.open(image_path)\n",
    "        recognized_data = pytesseract.image_to_string(\n",
    "            image, lang='eng',    # 한국어라면 lang='kor'\n",
    "            config=custom_oem_psm_config,\n",
    "            output_type=Output.DICT\n",
    "        )\n",
    "        print(recognized_data['text'])\n",
    "    print(\"Done\")\n",
    "\n",
    "# 위에서 준비한 문자 영역 파일들을 인식하여 얻어진 텍스트를 출력합니다.\n",
    "recognize_images(cropped_image_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fbd155",
   "metadata": {},
   "source": [
    "## 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e647faad",
   "metadata": {},
   "source": [
    "3가지 COR모델을 검증해본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e98bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 버전 확인\n",
    "import keras_ocr\n",
    "import pytesseract\n",
    "\n",
    "print(keras_ocr.__version__)\n",
    "print(pytesseract.__version__)\n",
    "# pytesseract는 tesseract-ocr에 종속적입니다. 아래 명령어를 통해 설치해야 할 수도 있습니다.\n",
    "# !sudo apt install tesseract-ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b337b9ee",
   "metadata": {},
   "source": [
    "## 1) 검증용 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a169806",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.getenv('HOME')+'/aiffel/ocr_python/text_images'\n",
    "img_file_path = [work_dir + f'/{i}.jpg' for i in range(8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb5f44e",
   "metadata": {},
   "source": [
    "## 2) keras-ocr, Tesseract로 테스트 진행 (구글 OCR API는 선택 사항)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9663011c",
   "metadata": {},
   "source": [
    "### 2-1) keras-ocr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783f317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import keras_ocr\n",
    "\n",
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [keras_ocr.tools.read(path) for path in img_file_path]\n",
    "prediction_groups = [pipeline.recognize([img]) for img in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893226a1",
   "metadata": {},
   "source": [
    "### 2-2) 테서랙트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efcf577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pytesseract import Output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OCR Engine modes(–oem):\n",
    "# 0 - Legacy engine only.\n",
    "# 1 - Neural nets LSTM engine only.\n",
    "# 2 - Legacy + LSTM engines.\n",
    "# 3 - Default, based on what is available.\n",
    "\n",
    "# Page segmentation modes(–psm):\n",
    "# 0 - Orientation and script detection (OSD) only.\n",
    "# 1 - Automatic page segmentation with OSD.\n",
    "# 2 - Automatic page segmentation, but no OSD, or OCR.\n",
    "# 3 - Fully automatic page segmentation, but no OSD. (Default)\n",
    "# 4 - Assume a single column of text of variable sizes.\n",
    "# 5 - Assume a single uniform block of vertically aligned text.\n",
    "# 6 - Assume a single uniform block of text.\n",
    "# 7 - Treat the image as a single text line.\n",
    "# 8 - Treat the image as a single word.\n",
    "# 9 - Treat the image as a single word in a circle.\n",
    "# 10 - Treat the image as a single character.\n",
    "# 11 - Sparse text. Find as much text as possible in no particular order.\n",
    "# 12 - Sparse text with OSD.\n",
    "# 13 - Raw line. Treat the image as a single text line, bypassing hacks that are Tesseract-specific."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c3cae0",
   "metadata": {},
   "source": [
    "## 3) 테스트 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04862724",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = 0\n",
    "\n",
    "print(f'Tesseract : Image {temp}')\n",
    "print(pytesseract.image_to_string(Image.open(img_file_path[temp])))\n",
    "\n",
    "print(f'keras_ocr : Image {temp}')\n",
    "keras_ocr.tools.drawAnnotations(image=images[temp],\n",
    "                                    predictions=prediction_groups[temp][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03633b2b",
   "metadata": {},
   "source": [
    "- 이미지 0\n",
    "\n",
    "케라스 ocr은 detect와 recognize 모두 잘 된다. 다만 가장 밑의 'COMMON'은 문자 사이 간격을 공백으로 인식해 한 단어로 인식하지 못했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa07908",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = 1\n",
    "\n",
    "print(f'Tesseract : Image {temp}')\n",
    "print(pytesseract.image_to_string(Image.open(img_file_path[temp])))\n",
    "\n",
    "print(f'keras_ocr : Image {temp}')\n",
    "keras_ocr.tools.drawAnnotations(image=images[temp],\n",
    "                                    predictions=prediction_groups[temp][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045db991",
   "metadata": {},
   "source": [
    "- 이미지 2 \n",
    "\n",
    "텍스트의 각도가 휘어있다. 그렇지만 케라스는 인식이 잘 된다. 초점이 흐려서 뭉개지는 텍스트는 인식률이 떨어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46655383",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = 2\n",
    "\n",
    "print(f'Tesseract : Image {temp}')\n",
    "print(pytesseract.image_to_string(Image.open(img_file_path[temp])))\n",
    "\n",
    "print(f'keras_ocr : Image {temp}')\n",
    "keras_ocr.tools.drawAnnotations(image=images[temp],\n",
    "                                    predictions=prediction_groups[temp][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81751fb",
   "metadata": {},
   "source": [
    "- 이미지 2\n",
    "\n",
    "처음으로 테서랙트가 텍스트를 잡아내긴 했지만 어디서 저런 텍스트가 나왔는지 모를만큼 인식이 잘 되지 않았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302acb54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = 3\n",
    "\n",
    "print(f'Tesseract : Image {temp}')\n",
    "print(pytesseract.image_to_string(Image.open(img_file_path[temp])))\n",
    "\n",
    "print(f'keras_ocr : Image {temp}')\n",
    "keras_ocr.tools.drawAnnotations(image=images[temp],\n",
    "                                    predictions=prediction_groups[temp][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f2b30",
   "metadata": {},
   "source": [
    "- 이미지 3\n",
    "\n",
    "테서랙트가 완벽하게 텍스트를 잡아냈다. 하지만 반은 완전히 날라갔다. 이렇게 보면 작동은 하는 것 같은데 뭐가 문제인지는 잘 모르겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fd9bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 4\n",
    "\n",
    "print(f'Tesseract : Image {temp}')\n",
    "print(pytesseract.image_to_string(Image.open(img_file_path[temp])))\n",
    "\n",
    "print(f'keras_ocr : Image {temp}')\n",
    "keras_ocr.tools.drawAnnotations(image=images[temp],\n",
    "                                    predictions=prediction_groups[temp][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f76897",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 5\n",
    "\n",
    "print(f'Tesseract : Image {temp}')\n",
    "print(pytesseract.image_to_string(Image.open(img_file_path[temp])))\n",
    "\n",
    "print(f'keras_ocr : Image {temp}')\n",
    "keras_ocr.tools.drawAnnotations(image=images[temp],\n",
    "                                    predictions=prediction_groups[temp][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b09480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = 6\n",
    "\n",
    "print(f'Tesseract : Image {temp}')\n",
    "print(pytesseract.image_to_string(Image.open(img_file_path[temp])))\n",
    "\n",
    "print(f'keras_ocr : Image {temp}')\n",
    "keras_ocr.tools.drawAnnotations(image=images[temp],\n",
    "                                    predictions=prediction_groups[temp][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ef348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = 7\n",
    "\n",
    "print(f'Tesseract : Image {temp}')\n",
    "print(pytesseract.image_to_string(Image.open(img_file_path[temp])))\n",
    "\n",
    "print(f'keras_ocr : Image {temp}')\n",
    "keras_ocr.tools.drawAnnotations(image=images[temp],\n",
    "                                    predictions=prediction_groups[temp][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a8d83e",
   "metadata": {},
   "source": [
    "## 4) 결과 분석과 결론 제시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3708b7b",
   "metadata": {},
   "source": [
    "테서렉트의 결과가 너무 좋지 못해서 비교가 힘들다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
